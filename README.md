# 2D Robot Localization: Particle Filter vs Neural Network

## Overview

This project explores the problem of **robot localization** in a 2D environment under noisy motion and sensing. The goal is to compare a **classical probabilistic approach**‚ÄîMonte Carlo Localization (Particle Filter)‚Äîwith a **learning-based approach** using a recurrent neural network (GRU/LSTM).

The robot operates in a continuous 20√ó20 unit world with fixed landmarks and does **not know its position a priori** (global localization). Both methods attempt to estimate the robot‚Äôs pose `(x, y, Œ∏)` over time using noisy control inputs and landmark observations.

---

## Problem Definition

- **State**
  - `(x, y)` position in a 2D plane  
  - `Œ∏` (theta): robot heading / orientation in radians  

- **Inputs**
  - Linear velocity `v`  
  - Angular velocity `œâ`  
  - Noisy range and bearing measurements to known landmarks  

- **Goal**
  - Estimate the robot‚Äôs pose as accurately as possible over time

---

## Environment

- Continuous 2D world: `20 √ó 20` units  
- 8 fixed landmarks with known positions  
- Motion noise:
  - Linear velocity noise `œÉ_v`
  - Angular velocity noise `œÉ_œâ`
- Sensor noise:
  - Range noise `œÉ_r`
  - Bearing noise `œÉ_b`

---

## Methods Compared

### 1. Monte Carlo Localization (Particle Filter)

- Represents belief as a **set of weighted particles**
- Each particle is a pose hypothesis `(x, y, Œ∏)`
- Algorithm loop:
  1. **Predict:** move particles using noisy motion model  
  2. **Update:** weight particles based on sensor likelihood  
  3. **Resample:** focus on high-probability hypotheses  

**Strengths**
- Handles uncertainty naturally
- Maintains multiple hypotheses
- Well-suited for global localization

This method serves as the **baseline**.

---

### 2. Neural Network Localization (GRU / LSTM)

- Recurrent neural network processes a **sequence** of:
  - Control inputs `(v, œâ)`
  - Landmark observations (range + bearing)
- Outputs a **single pose estimate** `(x, y, Œ∏)`
- Angle is predicted using `sin(Œ∏)` and `cos(Œ∏)` to avoid wraparound issues
- Trained using supervised learning on simulated trajectories

Two training strategies were explored:
- **Sequence-to-sequence:** predict pose at every timestep  
- **Sequence-to-final-step:** predict only the final pose of a trajectory  

---

## Key Observations

- The **particle filter consistently outperforms** the neural network in both position and orientation accuracy
- The neural network struggles with **global localization**, where no initial pose estimate is available
- Sequence-to-sequence training causes the network to **collapse toward the center** of the world due to ambiguity (‚Äúsafe averaging‚Äù)
- Sequence-to-final-step training removes this bias but produces **scattered predictions**, revealing fundamental ambiguity in global localization

---

## Results

The following visualizations are generated by the project:

- **Trajectory comparison:** ground truth vs particle filter vs neural network  
- **Position error vs time**
- **Orientation error vs time**

üìå **Figures**
- `trajectory_comparison.png`
- `localization_comparison.png`

---

## Why the Neural Network Struggles

- Global localization is inherently ambiguous
- The neural network outputs a **single pose**, while the particle filter maintains a **probability distribution**
- Without an initial pose prior, multiple locations are consistent with early sensor readings
- Particle filters delay commitment; neural networks must commit immediately

---

## Project Structure

This project is intentionally implemented as a **single Python file** for clarity:

```
‚îú‚îÄ‚îÄ robot_localization.py
‚îú‚îÄ‚îÄ localization_comparison.png
‚îú‚îÄ‚îÄ trajectory_comparison.png
‚îî‚îÄ‚îÄ README.md
```


---

## Requirements

- Python 3.8+
- NumPy
- Matplotlib
- PyTorch

Install dependencies:

```
pip install numpy matplotlib torch
```
How to Run
Run the full simulation with:

```
python robot_localization.py
```
This will:
- Generate training data
- Train the neural network
- Evaluate both methods
- Save comparison plots

## Limitations
Neural network performs offline estimation, not real-time filtering

No initial pose prior is provided

Network outputs a point estimate rather than a probability distribution

Environment is simplified (no obstacles, perfect data association)
Evaluate both methods

Save comparison plots
